## Survey Data Exploration

#Load the dataset
Import the required libraries.
import pandas as pd

#The dataset is available on the IBM Cloud at the below url.
dataset_url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv"

#Load the data available at dataset_url into a dataframe.
df = pd.read_csv(dataset_url)

#Explore the data set
#It is a good idea to print the top 5 rows of the dataset to get a feel of how the dataset will look.
#Display the top 5 rows and columns from your dataset.
# your coded goes here
df.head()

#Find out the number of rows and columns
#Start by exploring the numbers of rows and columns of data in the dataset.
#Print the number of rows in the dataset.
print("Number of rows:", df.shape[0])
-----Number of rows: 11552-----

#Print the number of columns in the dataset.
print("Number of columns:", df.shape[1])
-----Number of columns: 85------

#Identify the data types of each column
#Explore the dataset and identify the data types of each column.
#Print the datatype of all columns.
df.dtypes

#Print the mean age of the survey participants.
print("Mean age:", df["Age"].mean())
----Mean age: 30.77239449133718--------

#The dataset is the result of a world wide survey. Print how many unique countries are there in the Country column.
# Print the number of unique countries in the "Country" column
print("Number of unique countries:", df["Country"].nunique())
-----Number of unique countries: 135------

# Remove duplicate rows from the data frame
df = df.drop_duplicates()
# Print the number of rows in the data frame after removing duplicates
print("Number of rows after removing duplicates:", df.shape[0])
-----Number of rows after removing duplicates: 11398-------

# Print the number of unique rows in the data frame
print("Number of unique rows:", df.nunique())
-----Number of unique rows: Respondent      11398------------


# Count the number of blank rows in the "EdLevel" column
num_blank_rows = df["EdLevel"].isna().sum()
# Print the number of blank rows in the "EdLevel" column
print("Number of blank rows in the EdLevel column:", num_blank_rows)
-------Number of blank rows in the EdLevel column: 112-----------


# Count the number of missing rows in the "Country" column
num_missing_rows = df["Country"].isna().sum()
# Print the number of missing rows in the "Country" column
print("Number of missing rows in the Country column:", num_missing_rows)
------Number of missing rows in the Country column: 0--------------


# Find the majority category under the "Employment" column
majority_category = df["Employment"].value_counts().idxmax()
# Print the majority category under the "Employment" column
print("Majority category under the Employment column:", majority_category)
--------Majority category under the Employment column: Employed full-time--------

# Find the category with the minimum number of rows under the "UndergradMajor" column
min_category = df["UndergradMajor"].value_counts().idxmin()
# Print the category with the minimum number of rows under the "UndergradMajor" column
print("Category with the minimum number of rows under the UndergradMajor column:", min_catego
---Category with the minimum number of rows under the UndergradMajor column: A health science (ex. nursing, pharmacy, radiology)----


# Find the number of unique values in the "CompFreq" column
nunique_comp_freq = df["CompFreq"].nunique()
# Print the number of unique values in the "CompFreq" column
print("Number of unique values in the CompFreq column:", nunique_comp_freq)
-------Number of unique values in the CompFreq column: 3-----------


# Filter the DataFrame to include only rows where the "CompFreq" column is "Yearly"
yearly_df = df[df["CompFreq"] == "Yearly"]
# Count the number of rows in the filtered DataFrame
yearly_count = yearly_df.shape[0]
# Print the number of respondents being paid yearly
print("Number of respondents being paid yearly:", yearly_count)
----Number of respondents being paid yearly: 6073------------------


# Calculate the median age of survey respondents
median_age = df["Age"].median()
# Print the median age of survey respondents
print("Median age of survey respondents:", median_age)
-----Median age of survey respondents: 29.0---

# Calculate the median ConvertedComp of respondents who have identified themselves as ‘Woman’
median_comp_woman = df.loc[df["Gender"] == "Woman", "ConvertedComp"].median()
# Print the median ConvertedComp of respondents who have identified themselves as ‘Woman’
print("Median ConvertedComp of respondents who have identified themselves as ‘Woman’:", median_comp_woman)
------Median ConvertedComp of respondents who have identified themselves as ‘Woman’: 57708.0----

#import 
import matplotlib.pyplot as plt
# Create a histogram of the ages of survey respondents
plt.hist(df["Age"], bins=20)
plt.xlabel("Age")
plt.ylabel("Frequency")
plt.title("Histogram of Survey Respondent Ages")
plt.show()


# Calculate the median ConvertedComp before removing outliers
median_comp = df['ConvertedComp'].median()
# Print the median ConvertedComp before removing outliers
print("Median ConvertedComp before removing outliers:", median_comp)
---------Median ConvertedComp before removing outliers: 57745.0------



# Calculate the quartiles and IQR
Q1 = df['ConvertedComp'].quantile(0.25)
Q3 = df['ConvertedComp'].quantile(0.75)
IQR = Q3 - Q1
# Remove outliers
df_no_outliers = df[(df['ConvertedComp'] >= Q1 - 1.5*IQR) & (df['ConvertedComp'] <= Q3 + 1.5*IQR)]
# Calculate the median ConvertedComp after removing outliers
median_comp_no_outliers = df_no_outliers['ConvertedComp'].median()
# Print the median ConvertedComp after removing outliers
print("Median ConvertedComp after removing outliers:", median_comp_no_outliers)
----------Median ConvertedComp after removing outliers: 52704.0------


# Calculate the first and third quartiles and the interquartile range
q1, q3 = np.percentile(df['ConvertedComp'].dropna(), [25, 75])
iqr = q3 - q1
# Calculate the lower and upper bounds for outliers
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
# Remove outliers from the DataFrame
df_no_outliers = df[(df['ConvertedComp'].notnull()) & (df['ConvertedComp'] >= lower_bound) & (df['ConvertedComp'] <= upper_bound)]
# Calculate the mean ConvertedComp after removing outliers
mean_convertedcomp_no_outliers = df_no_outliers['ConvertedComp'].mean()
print(mean_convertedcomp_no_outliers)
---------59883.20838915799-----------






